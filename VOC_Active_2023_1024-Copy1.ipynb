{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bff38fe7",
   "metadata": {},
   "source": [
    "As of 1/5/2024: DOWNLOAD THE DATA IN UTC TIME! Otherwise daylight savings will break the script\n",
    "\n",
    "This is a working draft that is making improvements to the \"VOC_Active_2023_1024\" notebook.\n",
    "\n",
    "That one works fine, but it can be improved with some script modification and additional markup cells with comments/instructions.\n",
    "\n",
    "Major improvements needed include: \n",
    "* limit data to complete 24-hour periods, beginning and ending at midnight (cut off partial start and end days);\n",
    "* create a df of 1-min averages towards beginning of script to cut down on unneccesary processing time; \n",
    "* issues with processing data due to daylight savings (if study period spans the time shift, the code breaks unless the raw data is in UTC); \n",
    "* fix resampling (as long as we have at least one reading every minute, that is satisfactory for the summaries, graphs, and completeness assessment - the 30-sec resample may be an unnecessary step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b25ac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Iso8601Time  3579.feed_161522.tvoc_ch0\n",
      "0  2023-10-25T04:57:47.081000-04:00                         65\n",
      "1  2023-10-25T04:57:48.081000-04:00                         48\n",
      "2  2023-10-25T04:57:49.080000-04:00                         57\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1097796 entries, 0 to 1097795\n",
      "Data columns (total 2 columns):\n",
      " #   Column                     Non-Null Count    Dtype \n",
      "---  ------                     --------------    ----- \n",
      " 0   Iso8601Time                1097796 non-null  object\n",
      " 1   3579.feed_161522.tvoc_ch0  1097796 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 16.8+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Set the location to where you have saved the CSV file.\n",
    "location = 'VOC_snippet.csv'\n",
    "\n",
    "# Set the time zone first. Here are some examples: America/New_York, America/Los_Angeles, America/Chicago, Pacific/Honolulu.\n",
    "# The format generally follows the pattern \"America/Region\" or \"Continent/City\".\n",
    "timezone = 'America/New_York' \n",
    "\n",
    "# Read the CSV file and create a DataFrame\n",
    "df = pd.read_csv(location)\n",
    "# df = pd.read_csv(location, parse_dates=[\"Iso8601Time\"])\n",
    "\n",
    "# Print a preview of the beginning and end of df in order to determine \n",
    "# which data is in each column and the start and end times of recorded data\n",
    "print(df.head(3))\n",
    "# print(df.tail())\n",
    "df.info()\n",
    "\n",
    "# Replace with the actual original filename without extension\n",
    "# Make this more flexible code. User should not have to enter this. Do a string edit of the location variable\n",
    "original_filename = 'QQQQQQ' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6c10820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df912bb2",
   "metadata": {},
   "source": [
    "Yvonne comments on cell below:\n",
    "\n",
    "Can you get rid of any unnecessary commented code once this is finished? It looks like the first batch of code that is all hashmarked is code from the first draft that you commented out. \n",
    "\n",
    "Does the following code trim the data so that we use the data starting at 12am on the first day and ending at 11:59 pm (or 23:59) on the last day for our analysis?\n",
    "\n",
    "It looks like right now the code is printing the \"Percentage of missing data....\" message for every hour rather than for just the hours that have more than 25% of their data missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8b80711e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "                        Iso8601Time  3579.feed_161522.tvoc_ch0\n",
      "0  2023-10-25 04:57:47.081000-04:00                         65\n",
      "1  2023-10-25 04:57:48.081000-04:00                         48\n",
      "2  2023-10-25 04:57:49.080000-04:00                         57\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "# Convert the values in the first column to datetime format\n",
    "\n",
    "# df.info()\n",
    "# print(df['Iso8601Time'][0])\n",
    "# print(df.head(3))\n",
    "\n",
    "df.iloc[0:922924, 0] = pd.to_datetime(df.iloc[0:922924, 0], format='%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "# df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0], format='%Y-%m-%dT%H:%M:%S.%f')\n",
    "# df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0], format='%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "# df.iloc[:, 0] = pd.to_datetime(df[\"Iso8601Time\"], format='%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "# df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0], format='ISO8601', utc=True)\n",
    "\n",
    "print('=========')\n",
    "# print(df['Iso8601Time'][0])\n",
    "print(df.head(3))\n",
    "print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "27d178e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1097796 entries, 0 to 1097795\n",
      "Data columns (total 2 columns):\n",
      " #   Column                     Non-Null Count    Dtype \n",
      "---  ------                     --------------    ----- \n",
      " 0   Iso8601Time                1097796 non-null  object\n",
      " 1   3579.feed_161522.tvoc_ch0  1097796 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 16.8+ MB\n",
      "++++++++\n",
      "2023-10-25 04:57:47.081000-04:00\n",
      "2023-10-25 04:57:47.081000-04:00\n",
      "++++++++\n",
      "                        Iso8601Time  3579.feed_161522.tvoc_ch0\n",
      "0  2023-10-25 04:57:47.081000-04:00                         65\n",
      "1  2023-10-25 04:57:48.081000-04:00                         48\n",
      "2  2023-10-25 04:57:49.080000-04:00                         57\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "print('++++++++')\n",
    "print(df['Iso8601Time'][0])\n",
    "print(df['Iso8601Time'][0].tz_convert('America/New_York'))\n",
    "# df.set_index(df.columns[0], inplace=True)\n",
    "# df.head(3)\n",
    "\n",
    "# df['Iso8601Time'].tz_convert('America/New_York')\n",
    "\n",
    "print('++++++++')\n",
    "print(df.head(3))\n",
    "\n",
    "# df['Iso8601Time'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3ca563ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1097796 entries, 0 to 1097795\n",
      "Data columns (total 2 columns):\n",
      " #   Column                     Non-Null Count    Dtype \n",
      "---  ------                     --------------    ----- \n",
      " 0   Iso8601Time                1097796 non-null  object\n",
      " 1   3579.feed_161522.tvoc_ch0  1097796 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 16.8+ MB\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "index is not a valid DatetimeIndex or PeriodIndex",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pr/q674sh7s05q_ymjj752fz9qr0000gn/T/ipykernel_8111/3124239761.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Set the first column as the index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Set the time zone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimezone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Find the first and last valid timestamps in the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfirst_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, tz, axis, level, copy)\u001b[0m\n\u001b[1;32m  10382\u001b[0m         \u001b[0;36m3\u001b[0m    \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10383\u001b[0m         \u001b[0;36m4\u001b[0m    \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10384\u001b[0m         \u001b[0mName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10386\u001b[0;31m         \u001b[0mThe\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdatetimes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10387\u001b[0m         \u001b[0mdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10389\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2016-01-01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2016-02-01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(ax, tz)\u001b[0m\n\u001b[1;32m  10365\u001b[0m     def truncate(\n\u001b[1;32m  10366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNDFrameT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10367\u001b[0m     ) -> NDFrameT:\n\u001b[1;32m  10368\u001b[0m         \"\"\"\n\u001b[0;32m> 10369\u001b[0;31m         \u001b[0mTruncate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mSeries\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mafter\u001b[0m \u001b[0msome\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10371\u001b[0m         \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0museful\u001b[0m \u001b[0mshorthand\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mboolean\u001b[0m \u001b[0mindexing\u001b[0m \u001b[0mbased\u001b[0m \u001b[0mon\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10372\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0mabove\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbelow\u001b[0m \u001b[0mcertain\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: index is not a valid DatetimeIndex or PeriodIndex"
     ]
    }
   ],
   "source": [
    "# Convert the values in the first column to datetime format\n",
    "# df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0], format='%Y-%m-%dT%H:%M:%S.%f')\n",
    "df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0], format='%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "\n",
    "df.info()\n",
    "\n",
    "# Set the first column as the index\n",
    "df.set_index(df.columns[0], inplace=True)\n",
    "\n",
    "# Set the time zone\n",
    "df = df.tz_convert(timezone)\n",
    "\n",
    "# Find the first and last valid timestamps in the DataFrame\n",
    "first_timestamp = df.index.min()\n",
    "last_timestamp = df.index.max()\n",
    "\n",
    "# Round down the first timestamp to the nearest hour and add 1 hour to it to set it as the desired start time\n",
    "desired_start_time = first_timestamp.floor('H') + pd.Timedelta(hours=1)\n",
    "\n",
    "# Round down the last timestamp to the nearest hour to set it as the desired end time\n",
    "desired_end_time = last_timestamp.floor('H')\n",
    "\n",
    "# Filter the DataFrame to keep rows within the desired start and end times\n",
    "df = df[(df.index >= desired_start_time) & (df.index <= desired_end_time)]\n",
    "\n",
    "# reprint head and tail to verify correct start and end times\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2954ae05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Start and end cannot both be tz-aware with different timezones",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/arrays/datetimes.py:2423\u001b[0m, in \u001b[0;36m_infer_tz_from_endpoints\u001b[0;34m(start, end, tz)\u001b[0m\n\u001b[1;32m   2422\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2423\u001b[0m     inferred_tz \u001b[38;5;241m=\u001b[39m \u001b[43mtimezones\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_tzinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   2425\u001b[0m     \u001b[38;5;66;03m# infer_tzinfo raises AssertionError if passed mismatched timezones\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/tslibs/timezones.pyx:368\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timezones.infer_tzinfo\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Inputs must both have the same timezone, UTC-04:00 != UTC-05:00",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m total_seconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Loop over each hour of data\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# NOTE instead of creating a df over and over again for each hour of data, wouldn't it be more efficient to use \u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# something like a count function?\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hour_start \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdate_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1H\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Get the hour end time\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     hour_end \u001b[38;5;241m=\u001b[39m hour_start \u001b[38;5;241m+\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimedelta(hours\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Subset the data for the current hour\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:945\u001b[0m, in \u001b[0;36mdate_range\u001b[0;34m(start, end, periods, freq, tz, normalize, name, inclusive, unit, **kwargs)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m freq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m com\u001b[38;5;241m.\u001b[39many_none(periods, start, end):\n\u001b[1;32m    943\u001b[0m     freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 945\u001b[0m dtarr \u001b[38;5;241m=\u001b[39m \u001b[43mDatetimeArray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_range\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperiods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperiods\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclusive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclusive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatetimeIndex\u001b[38;5;241m.\u001b[39m_simple_new(dtarr, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/arrays/datetimes.py:422\u001b[0m, in \u001b[0;36mDatetimeArray._generate_range\u001b[0;34m(cls, start, end, periods, freq, tz, normalize, ambiguous, nonexistent, inclusive, unit)\u001b[0m\n\u001b[1;32m    420\u001b[0m left_inclusive, right_inclusive \u001b[38;5;241m=\u001b[39m validate_inclusive(inclusive)\n\u001b[1;32m    421\u001b[0m start, end \u001b[38;5;241m=\u001b[39m _maybe_normalize_endpoints(start, end, normalize)\n\u001b[0;32m--> 422\u001b[0m tz \u001b[38;5;241m=\u001b[39m \u001b[43m_infer_tz_from_endpoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;66;03m# Localize the start and end arguments\u001b[39;00m\n\u001b[1;32m    426\u001b[0m     start_tz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m start\u001b[38;5;241m.\u001b[39mtz\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/arrays/datetimes.py:2426\u001b[0m, in \u001b[0;36m_infer_tz_from_endpoints\u001b[0;34m(start, end, tz)\u001b[0m\n\u001b[1;32m   2423\u001b[0m     inferred_tz \u001b[38;5;241m=\u001b[39m timezones\u001b[38;5;241m.\u001b[39minfer_tzinfo(start, end)\n\u001b[1;32m   2424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   2425\u001b[0m     \u001b[38;5;66;03m# infer_tzinfo raises AssertionError if passed mismatched timezones\u001b[39;00m\n\u001b[0;32m-> 2426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart and end cannot both be tz-aware with different timezones\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2428\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   2430\u001b[0m inferred_tz \u001b[38;5;241m=\u001b[39m timezones\u001b[38;5;241m.\u001b[39mmaybe_get_tz(inferred_tz)\n\u001b[1;32m   2431\u001b[0m tz \u001b[38;5;241m=\u001b[39m timezones\u001b[38;5;241m.\u001b[39mmaybe_get_tz(tz)\n",
      "\u001b[0;31mTypeError\u001b[0m: Start and end cannot both be tz-aware with different timezones"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame to remove negative values\n",
    "df = df[df >= 0]\n",
    "\n",
    "# Calculate the total number of seconds in an hour\n",
    "total_seconds = 60 * 60\n",
    "\n",
    "# Loop over each hour of data\n",
    "# NOTE instead of creating a df over and over again for each hour of data, wouldn't it be more efficient to use \n",
    "# something like a count function?\n",
    "for hour_start in pd.date_range(start=df.index.min(), end=df.index.max(), freq='1H'):\n",
    "    # Get the hour end time\n",
    "    hour_end = hour_start + pd.Timedelta(hours=1)\n",
    "    \n",
    "    # Subset the data for the current hour\n",
    "    hour_data = df.loc[(df.index >= hour_start) & (df.index < hour_end)]\n",
    "\n",
    "    # Resample the data to 1-second intervals and count the number of data points per second\n",
    "    resampled_df = hour_data.resample('1S').count()\n",
    "\n",
    "    # Limit the resampled DataFrame to 1 hour of data\n",
    "    resampled_df = resampled_df.iloc[:total_seconds]\n",
    "\n",
    "    # Calculate the number of missing seconds\n",
    "    missing_seconds = total_seconds - resampled_df.iloc[:, 0].sum()\n",
    "\n",
    "    # Calculate the percentage of missing data\n",
    "    missing_percentage = (missing_seconds / total_seconds) * 100\n",
    "\n",
    "    # Print the percentage of missing data for the hour if larger than 25%\n",
    "    if missing_percentage >= 25:\n",
    "        print(f\"Percentage of missing data in hour from {hour_start} to {hour_end}: {missing_percentage:.2f}%\")\n",
    "\n",
    "# Resample the data to 30-second intervals and calculate the mean\n",
    "resampled_data_30s = df.resample('30S').mean()\n",
    "\n",
    "# Count the number of readings equal to or greater than 500 ppb\n",
    "count = 0\n",
    "for data in resampled_data_30s.iloc[:, 0]:\n",
    "    if data >= 500:\n",
    "        count += 1\n",
    "\n",
    "# Calculate the percentage\n",
    "percentage = (count / len(resampled_data_30s.iloc[:, 0])) * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of readings equal to or greater than 500 ppb:\", count)\n",
    "print(\"Percentage of data exceeding 500 ppb:\", format(percentage, '.2f'), \"%\")\n",
    "# Would also be helpful to have the dates when those exceedances happened"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd9045f",
   "metadata": {},
   "source": [
    "Figure 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597da605",
   "metadata": {},
   "source": [
    "Yvonne comments on cell below:\n",
    "\n",
    "Should we be concerned about the Userwarning regarding the timezone being dropped?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adaeaf5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# It would be better if the analysis and graph were calculated from month-long data\n",
    "# i.e. July 8 - AUgust 8. Not just July, August, Sept, etc.\n",
    "# We don't install monitors on the first of the month so July data could just be 5 days!\n",
    "# X-axis labels would then be \"Month1, Month2, etc.\" or something similar. Also, what is going on with\n",
    "# the daily averages here? There should be no partial days used. Is that happening?\n",
    "\n",
    "# Calculate the daily averages\n",
    "daily_averages = resampled_data_30s.resample('D').mean()\n",
    "\n",
    "# Resample the daily averages to monthly intervals and calculate the mean\n",
    "monthly_averages = daily_averages.resample('M').mean()\n",
    "\n",
    "# Convert the index to a PeriodIndex with timezone awareness\n",
    "daily_averages.index = daily_averages.index.to_period('D')\n",
    "\n",
    "# Calculate the standard deviation of daily values from the monthly average\n",
    "std_values = daily_averages.groupby(daily_averages.index.to_timestamp('M')).std()\n",
    "\n",
    "# Find the month with the highest average\n",
    "highest_month = monthly_averages.iloc[:, 0].idxmax()\n",
    "highest_average = monthly_averages.iloc[:, 0].max()\n",
    "std_dev = monthly_averages.iloc[:, 0].std()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Highest monthly average was in {highest_month.strftime('%B %Y')} at {highest_average:.3f} ± {std_dev:.3f} ppb\")\n",
    "\n",
    "# Set the figure DPI\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Generate the error bar plot\n",
    "plt.errorbar(monthly_averages.index, monthly_averages.iloc[:, 0], yerr=std_values.iloc[:, 0], fmt='o', capsize=15, color='black')\n",
    "\n",
    "# Format the x-axis labels\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator())\n",
    "\n",
    "# Adjust the location of x-axis labels\n",
    "plt.gca().set_xticks(monthly_averages.index)  # Set the tick positions to match the x-values\n",
    "\n",
    "# Adjust the x-axis labels rotation\n",
    "plt.xticks(rotation=45, fontsize=7)\n",
    "\n",
    "# Adjust the y-axis tick spacing\n",
    "plt.yticks(range(0, 300, 50), fontsize=7)\n",
    "\n",
    "# Set the font for axis labels\n",
    "plt.gca().set_xlabel('Month', fontname='Times New Roman', fontsize=9)\n",
    "plt.gca().set_ylabel('VOC Concentration (ppb)', fontname='Times New Roman', fontsize=9)\n",
    "\n",
    "# Set the font for title\n",
    "plt.gca().set_title('Monthly Average VOC Levels', fontname='Times New Roman', fontsize=10)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('VOC Month Avg.png', dpi=300)\n",
    "\n",
    "# Adjust the figure size (modify width and height as needed)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758bf49a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monthly_mean = float(monthly_averages.mean())\n",
    "print(\"the mean of monthly averages is {}\".format(monthly_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b06d15",
   "metadata": {},
   "source": [
    "Figure 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ad603",
   "metadata": {},
   "source": [
    "Yvonne notes on cell below:\n",
    "\n",
    "In the third block you have comments \"Notice: please specify the start(end) date here\"  Aren't these variables/dates defined in the first block/cell above?\n",
    "\n",
    "For the y axis ticks, as written in the script, will we have to modify the line below defining y-axis tick spacing if our data has a different range? FOr example, if our VOC levels are above 600? If so, is there a way to automatically set this (without the user having to define it) based on the maximum value of these daily averages, so that it would be the nearest multiple of 100 above the daily average value that is being plotted?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723aa616",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# FOR EACH FILE, Specify the date period here for the Daily Avg graph\n",
    "# This should omit the partial start and end dates\n",
    "start_date = '2023-09-27'\n",
    "end_date = '2024-01-21'\n",
    "start_date = pd.Timestamp(start_date, tz=timezone) \n",
    "end_date = pd.Timestamp(end_date, tz=timezone)\n",
    "\n",
    "# Resample the data to daily intervals and calculate the mean\n",
    "grouped = resampled_data_30s.resample('D').mean()\n",
    "std_values = resampled_data_30s.resample('D').std()\n",
    "\n",
    "# Select the desired date range\n",
    "selected_grouped = grouped[start_date:end_date]\n",
    "selected_std_values = std_values[start_date:end_date]\n",
    "\n",
    "# Configure plot settings\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Generate the line plot with connected data points\n",
    "plt.plot(selected_grouped.index, selected_grouped.iloc[:, 0], marker='o', linestyle='-', color='black', linewidth=0.3)\n",
    "\n",
    "# Add error bars\n",
    "plt.errorbar(selected_grouped.index, selected_grouped.iloc[:, 0], yerr=selected_std_values.iloc[:, 0], fmt='none', color='black', capsize=15)\n",
    "\n",
    "# create the x-labels variable to use for x-tick formatting\n",
    "x_labels = [date.strftime('%m-%d') for date in selected_grouped.index]\n",
    "\n",
    "# Format the x-axis labels\n",
    "plt.xticks(selected_grouped.index[::5], x_labels[::5] , rotation=45, fontsize=7)\n",
    "\n",
    "## Format the x-axis labels (original script)\n",
    "#plt.xticks(selected_grouped.index, [date.strftime('%m-%d') for date in selected_grouped.index], rotation=45, fontsize=7)\n",
    "\n",
    "# Set the x-axis tick positions to match the x-values\n",
    "plt.gca().set_xticks(selected_grouped.index)\n",
    "\n",
    "# Calculate the maximum value of daily averages\n",
    "max_daily_average = selected_grouped.iloc[:, 0].max()\n",
    "\n",
    "# Default is to set the y-axis tick spacing at 100, we often need to increase this to accomodate data\n",
    "y_tick_spacing = 100\n",
    "\n",
    "# Calculate the y-axis tick range dynamically\n",
    "# NOTE we need to change this so the range includes the maximum 30s value\n",
    "#y_tick_range = range(0, int(max_daily_average) + y_tick_spacing, y_tick_spacing)\n",
    "\n",
    "y_tick_range = range(0, 800 + y_tick_spacing, y_tick_spacing)\n",
    "\n",
    "# Adjust the y-axis tick spacing and font size\n",
    "plt.yticks(y_tick_range, fontsize=7)\n",
    "\n",
    "# Set the x-axis and y-axis labels\n",
    "plt.xlabel('Date', fontname='Times New Roman', fontsize=9)\n",
    "plt.ylabel('VOC Concentration (ppb)', fontname='Times New Roman', fontsize=9)\n",
    "\n",
    "# Set the title with the start and end dates\n",
    "title = f\"Daily Average VOC Levels: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\"\n",
    "plt.title(title, fontname='Times New Roman', fontsize=10)\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('VOC Daily Avg.png', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "print(\"The highest daily average is {}\".format(max_daily_average))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c1219",
   "metadata": {},
   "source": [
    "Yvonne comments on cell below:\n",
    "\n",
    "The calculation and reporting of readings above 500 ppb should be done for the total time period (from the first full day to the last full day of the data collected),  not the selected time period used to generate the graph below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5ed2f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# FOR EACH FILE, specify the date and time period here for the VOC by minute graph\n",
    "start_datetime = '2023-12-23 03:05'\n",
    "end_datetime = '2023-12-23 05:55'\n",
    "start_datetime = pd.Timestamp(start_datetime, tz=timezone)\n",
    "end_datetime = pd.Timestamp(end_datetime, tz=timezone)\n",
    "\n",
    "\n",
    "## Right now this is graphing 30s readings. It should be graphing 1 minute readings.\n",
    "# Filter the dataset based on the desired date and time range\n",
    "filtered_data = resampled_data_30s[(resampled_data_30s.index >= start_datetime) & (resampled_data_30s.index <= end_datetime)]\n",
    "\n",
    "# Configure plot settings\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the line plot\n",
    "plt.plot(filtered_data.index, filtered_data.iloc[:, 0], color='black', linewidth=1)\n",
    "\n",
    "# Extract the time component from the filtered_data index\n",
    "x_labels = [date.strftime('%H:%M') for date in filtered_data.index]\n",
    "\n",
    "# Set the x-axis tick labels\n",
    "plt.xticks(filtered_data.index[::20], x_labels[::20], rotation=45, fontsize=7)  # Display every 10th label\n",
    "\n",
    "# Set the y-axis tick labels font size\n",
    "plt.yticks(fontsize=7)\n",
    "\n",
    "# Set the x-axis label\n",
    "plt.xlabel('Time', fontname='Times New Roman', fontsize=9)\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel('VOC Concentration (ppb)', fontname='Times New Roman', fontsize=9)\n",
    "\n",
    "# Set the title with the specified date\n",
    "title = f\"VOC Levels Per Minute on {start_datetime.strftime('%Y-%m-%d')}\"\n",
    "plt.title(title, fontname='Times New Roman', fontsize=10)\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('VOC by Minute.png', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Resample the data to 1-minute intervals and calculate the mean\n",
    "resampled_data_1min = df.resample('1T').mean()\n",
    "\n",
    "# # Fill any missing values (NaN) in the DataFrame by forward-filling (ffill) the previous value\n",
    "# resampled_data_1min.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Filter the dataset based on the desired date and time range\n",
    "filtered_data_1min = resampled_data_1min[(resampled_data_1min.index >= start_datetime) & (resampled_data_1min.index <= end_datetime)]\n",
    "\n",
    "# Find the highest 1 minute ppb value\n",
    "highest_1min_ppb = filtered_data_1min.iloc[:, 0].max()\n",
    "\n",
    "# Print the result\n",
    "print(\"The highest 1 minute ppb value from the time period is {}\".format(highest_1min_ppb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75735b62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter the dataset based on the desired date range.\n",
    "studyperiod_data_1min = resampled_data_1min[(resampled_data_1min.index >= start_date) & (resampled_data_1min.index <= end_date)]\n",
    "\n",
    "# Find the highest 1 minute ppb value\n",
    "highest_1min_ppb = studyperiod_data_1min.iloc[:, 0].max()\n",
    "\n",
    "# Print the result\n",
    "print(\"The highest 1 minute ppb value from the entire study period is {}\".format(highest_1min_ppb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0677a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure what this block is doing and why it is HERE\n",
    "# The script should set the time to local and resample to 1 minutes averages at the beginning, right?\n",
    "# We need to handle that 1 minute averaging appropriately (null values)\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Convert the index to local time (assuming the original data is in UTC)\n",
    "resampled_data_1min_local = resampled_data_1min.tz_convert(timezone)  # Replace 'Your_Local_Timezone' with your actual local timezone\n",
    "\n",
    "# Split the local time index into separate date and time columns\n",
    "resampled_data_1min_local['Date'] = resampled_data_1min_local.index.date\n",
    "resampled_data_1min_local['Time'] = resampled_data_1min_local.index.time\n",
    "\n",
    "# Drop the original datetime index\n",
    "resampled_data_1min_local.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create a new DataFrame with the desired columns\n",
    "new_df = pd.DataFrame({\n",
    "    'Date': resampled_data_1min_local['Date'],\n",
    "    'Time': resampled_data_1min_local['Time'],\n",
    "    '1-Minute Averages (ppb)': resampled_data_1min_local.iloc[:, 0]\n",
    "})\n",
    "\n",
    "output_filename = f\"{original_filename}_processed.csv\"\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "new_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"Processed data saved to {output_filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d016ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
